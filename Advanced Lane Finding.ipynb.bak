{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Lane Finding Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources\n",
    "extracting frames from video:  https://stackoverflow.com/questions/33311153/python-extracting-and-saving-video-frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#command line functions\n",
    "#os.rmdir('../Undistorted Test Images')\n",
    "#os.mkdir('../Undistorted_Test_Images')\n",
    "#os.remove('../overpass.mp4')\n",
    "#os.remove('../pavement.mp4')\n",
    "#os.remove('../leaves.mp4')\n",
    "#os.remove('../shadows.mp4')\n",
    "#os.remove('../test_images/undistorted_straight_lines2.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib qt\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create test images from the challenge videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video overpass.mp4\n",
      "[MoviePy] Writing video overpass.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 36.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: overpass.mp4 \n",
      "\n",
      "[MoviePy] >>>> Building video pavement.mp4\n",
      "[MoviePy] Writing video pavement.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 37.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: pavement.mp4 \n",
      "\n",
      "[MoviePy] >>>> Building video leaves.mp4\n",
      "[MoviePy] Writing video leaves.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 37.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: leaves.mp4 \n",
      "\n",
      "[MoviePy] >>>> Building video shadows.mp4\n",
      "[MoviePy] Writing video shadows.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 37.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: shadows.mp4 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "overpass = VideoFileClip(\"../challenge_video.mp4\").subclip(4.2,4.3)\n",
    "overpass.write_videofile('overpass.mp4', audio=False)\n",
    "pavement = VideoFileClip(\"../challenge_video.mp4\").subclip(6,6.1)\n",
    "pavement.write_videofile('pavement.mp4', audio=False)\n",
    "leaves = VideoFileClip(\"../harder_challenge_video.mp4\").subclip(3,3.1)\n",
    "leaves.write_videofile('leaves.mp4', audio=False)\n",
    "shadows = VideoFileClip(\"../harder_challenge_video.mp4\").subclip(7,7.1)\n",
    "shadows.write_videofile('shadows.mp4', audio=False)\n",
    "\n",
    "#vidcap = cv2.VideoCapture('./challenge_output.mp4')\n",
    "#vidcap = VideoFileClip(\"../challenge_video.mp4\").subclip(4,4.5)\n",
    "\n",
    "\n",
    "#vidcap = cv2.VideoCapture('../overpass.mp4')\n",
    "#print('reading image')\n",
    "#success,image = vidcap.read()\n",
    "#count = 0\n",
    "#success = True\n",
    "#while success:\n",
    "#  cv2.imwrite('overpass_frame%d.jpg' % count, image)     # save frame as JPEG file\n",
    "#  success,image = vidcap.read()\n",
    "#  print('Read a new frame: ', success)\n",
    "#  count += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_undistort(img, objpoints, imgpoints):\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    return undist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First, I'll compute the camera calibration using chessboard images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('../camera_cal/calibration*.jpg')\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6),None)\n",
    "\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        img = cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "        plt.imshow(img)\n",
    "        #cv2.imshow('img',img)\n",
    "        #cv2.waitKey(500)\n",
    "\n",
    "\n",
    "# TODO: Write a function that takes an image, object points, and image points\n",
    "# performs the camera calibration, image distortion correction and \n",
    "# returns the undistorted image\n",
    "img = cv2.imread('../camera_cal/calibration1.jpg')\n",
    "undistorted = cal_undistort(img, objpoints, imgpoints)\n",
    "cv2.imwrite('../camera_cal/undistorted.jpg', undistorted)\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=50)\n",
    "ax2.imshow(undistorted)\n",
    "ax2.set_title('Undistorted Image', fontsize=50)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Input and correct raw images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = os.listdir(\"../test_images/\")\n",
    "\n",
    "for name in file_list:\n",
    "    image = mpimg.imread('../test_images/%s'  %(name))   #read in the image\n",
    "    undistorted = cal_undistort(image, objpoints, imgpoints)\n",
    "    cv2.imwrite('../Undistorted_Test_Images/undistorted_%s'  %(name), undistorted)\n",
    "\n",
    "#gray = cv2.cvtColor(image,cv2.COLOR_RGB2GRAY) # grayscale the image\n",
    "#blur_gray = gaussian_blur(gray, 5)  #add gaussian blur\n",
    "#edges = cv2.Canny(blur_gray, 50, 150)  # add canny "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
