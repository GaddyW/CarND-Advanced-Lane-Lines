{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Lane Finding Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources\n",
    "extracting frames from video:  https://stackoverflow.com/questions/33311153/python-extracting-and-saving-video-frames\n",
    "a.\tReal time lane detection for autonomous vehicles, Assidiq et. al.\n",
    "b.\tSaad Bedros, Hough Transform and Thresholding lecture, University of Minnesota \n",
    "c.\tLane detection techniques review, Kaur and Kumar\n",
    "d.\tAn Adaptive Method for Lane Marking Detection Based on HSI Color Model, Tran and Cho\n",
    "e.\tLANE CHANGE DETECTION AND TRACKING FOR A SAFE-LANE APPROACH IN REAL TIME VISION BASED NAVIGATION SYSTEMS, Somasundaram, Ramachandran, Kavitha\n",
    "f.\tA Robust Lane Detection and Departure Warning System, Mrinal Haloi and Dinesh Babu Jayagopi\n",
    "g.\tSteerable filters\n",
    "h.\tA layered approach to robust lane detection at night, Hayes and Pankati\n",
    "i.\tSHADOW DETECTION USING COLOR AND EDGE INFORMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#command line functions\n",
    "#os.rmdir('../Undistorted Test Images')\n",
    "#os.mkdir('../Undistorted_Test_Images')\n",
    "#os.remove('../overpass.mp4')\n",
    "#os.remove('../pavement.mp4')\n",
    "#os.remove('../leaves.mp4')\n",
    "#os.remove('../shadows.mp4')\n",
    "#os.remove('../test_images/undistorted_straight_lines2.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-890d4d5c5fe6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib qt\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create test images from the challenge videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video ../test_images/overpass.mp4\n",
      "[MoviePy] Writing video ../test_images/overpass.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 39.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: ../test_images/overpass.mp4 \n",
      "\n",
      "[MoviePy] >>>> Building video ../test_images/pavement.mp4\n",
      "[MoviePy] Writing video ../test_images/pavement.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 44.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: ../test_images/pavement.mp4 \n",
      "\n",
      "[MoviePy] >>>> Building video ../test_images/leaves.mp4\n",
      "[MoviePy] Writing video ../test_images/leaves.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 43.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: ../test_images/leaves.mp4 \n",
      "\n",
      "[MoviePy] >>>> Building video ../test_images/shadows.mp4\n",
      "[MoviePy] Writing video ../test_images/shadows.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 43.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "overpass = VideoFileClip(\"../challenge_video.mp4\").subclip(4.2,4.3)\n",
    "overpass.write_videofile('../test_images/overpass.mp4', audio=False)\n",
    "pavement = VideoFileClip(\"../challenge_video.mp4\").subclip(6,6.1)\n",
    "pavement.write_videofile('../test_images/pavement.mp4', audio=False)\n",
    "leaves = VideoFileClip(\"../harder_challenge_video.mp4\").subclip(3,3.1)\n",
    "leaves.write_videofile('../test_images/leaves.mp4', audio=False)\n",
    "shadows = VideoFileClip(\"../harder_challenge_video.mp4\").subclip(7,7.1)\n",
    "shadows.write_videofile('../test_images/shadows.mp4', audio=False)\n",
    "\n",
    "\n",
    "vidcap = cv2.VideoCapture('overpass.mp4')\n",
    "print('reading image')\n",
    "success,image = vidcap.read()\n",
    "count = 0\n",
    "success = True\n",
    "while success:\n",
    "  cv2.imwrite('overpass_frame%d.jpg' % count, image)     \n",
    "  success,image = vidcap.read()\n",
    "  print('Read a new frame: ', success)\n",
    "  count += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_undistort(img, objpoints, imgpoints):\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    return undist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First, I'll compute the camera calibration using chessboard images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('../camera_cal/calibration*.jpg')\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6),None)\n",
    "\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        img = cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "        plt.imshow(img)\n",
    "        #cv2.imshow('img',img)\n",
    "        #cv2.waitKey(500)\n",
    "\n",
    "\n",
    "# TODO: Write a function that takes an image, object points, and image points\n",
    "# performs the camera calibration, image distortion correction and \n",
    "# returns the undistorted image\n",
    "img = cv2.imread('../camera_cal/calibration1.jpg')\n",
    "undistorted = cal_undistort(img, objpoints, imgpoints)\n",
    "cv2.imwrite('../camera_cal/undistorted.jpg', undistorted)\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=50)\n",
    "ax2.imshow(undistorted)\n",
    "ax2.set_title('Undistorted Image', fontsize=50)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Input and correct raw images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = os.listdir(\"../test_images/\")\n",
    "\n",
    "for name in file_list:\n",
    "    image = mpimg.imread('../test_images/%s'  %(name))   #read in the image\n",
    "    undistorted = cal_undistort(image, objpoints, imgpoints)\n",
    "    cv2.imwrite('../Undistorted_Test_Images/undistorted_%s'  %(name), undistorted)\n",
    "\n",
    "#gray = cv2.cvtColor(image,cv2.COLOR_RGB2GRAY) # grayscale the image\n",
    "#blur_gray = gaussian_blur(gray, 5)  #add gaussian blur\n",
    "#edges = cv2.Canny(blur_gray, 50, 150)  # add canny "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
