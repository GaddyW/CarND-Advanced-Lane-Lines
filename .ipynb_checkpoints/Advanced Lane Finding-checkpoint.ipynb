{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Lane Finding Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources\n",
    "extracting frames from video:  https://stackoverflow.com/questions/33311153/python-extracting-and-saving-video-frames\n",
    "a.\tReal time lane detection for autonomous vehicles, Assidiq et. al.\n",
    "b.\tSaad Bedros, Hough Transform and Thresholding lecture, University of Minnesota \n",
    "c.\tLane detection techniques review, Kaur and Kumar\n",
    "d.\tAn Adaptive Method for Lane Marking Detection Based on HSI Color Model, Tran and Cho\n",
    "e.\tLANE CHANGE DETECTION AND TRACKING FOR A SAFE-LANE APPROACH IN REAL TIME VISION BASED NAVIGATION SYSTEMS, Somasundaram, Ramachandran, Kavitha\n",
    "f.\tA Robust Lane Detection and Departure Warning System, Mrinal Haloi and Dinesh Babu Jayagopi\n",
    "g.\tSteerable filters\n",
    "h.\tA layered approach to robust lane detection at night, Hayes and Pankati\n",
    "i.\tSHADOW DETECTION USING COLOR AND EDGE INFORMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#command line functions\n",
    "#os.rmdir('../Undistorted Test Images')\n",
    "#os.mkdir('../Undistorted_Test_Images')\n",
    "#os.remove('../overpass.mp4')\n",
    "#os.remove('../pavement.mp4')\n",
    "#os.remove('../leaves.mp4')\n",
    "#os.remove('../shadows.mp4')\n",
    "#os.remove('../test_images/undistorted_straight_lines2.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "grayscale - doesn't do well on bright roads.  I tried using red instead.\n",
    "magnitude - does great on black road, even way out to a distance, disappears on light color road\n",
    "yellow with s and h - works well, but not out to a distance, even on changing road and can't handle shadows\n",
    "white with l, s, and r - almost as good as magnitude on black roads, much better on imperfect roads\n",
    "shadows - sobel_y doesn't do so well, but sobel_x and magnitude are pretty good "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib qt\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_undistort(img, objpoints, imgpoints):\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    return undist\n",
    "\n",
    "\n",
    "def threshold(image, thresh_min=0, thresh_max=255, scale = True):\n",
    "    if scale:\n",
    "        scaled = np.uint8(255*image/np.max(image)) # 4) Scale to 8-bit (0 - 255) then convert to type = np.uint8\n",
    "    else:\n",
    "        scaled = image\n",
    "    binary_output = np.zeros_like(scaled)\n",
    "    # Masking for region of interest\n",
    "    mask = np.zeros_like(scaled)   \n",
    "    ignore_mask_color = 100   \n",
    "    imshape = scaled.shape\n",
    "    vertices = np.array([[(0,660),(0, 420), (imshape[1], 420), (imshape[1],660)]], dtype=np.int32)\n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "\n",
    "    \n",
    "    binary_output[(scaled >= thresh_min) & (scaled <= thresh_max) & (mask > 0)] = 1\n",
    "    return binary_output\n",
    "\n",
    "def gaussian_blur(img, kernel_size):\n",
    "    \"\"\"Applies a Gaussian Noise kernel\"\"\"\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "def dir_threshold(img, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    \n",
    "    # Apply the following steps to img\n",
    "    # 1) Convert to grayscale\n",
    "    # 2) Take the gradient in x and y separately\n",
    "    # 3) Take the absolute value of the x and y gradients\n",
    "    # 4) Use np.arctan2(abs_sobely, abs_sobelx) to calculate the direction of the gradient \n",
    "    # 5) Create a binary mask where direction thresholds are met\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    gray = image[:,:,0]#cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) # 1) Convert to grayscale\n",
    "    sobel_x = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 1, 0,ksize=sobel_kernel))\n",
    "    sobel_y = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 0, 1,ksize=sobel_kernel))\n",
    "    dir_grad = np.absolute(np.arctan2(sobel_y,sobel_x))\n",
    "    print(np.amin(dir_grad))\n",
    "    print(np.amax(dir_grad))\n",
    "    #scaled_sobel = np.uint8(255*dir_grad/np.max(dir_grad)) # 4) Scale to 8-bit (0 - 255) then convert to type = np.uint8\n",
    "    binary_output = np.zeros_like(dir_grad)\n",
    "    \n",
    "    # Masking for region of interest\n",
    "    mask = np.zeros_like(dir_grad)   \n",
    "    ignore_mask_color = 100   \n",
    "    imshape = dir_grad.shape\n",
    "    vertices = np.array([[(0,660),(0, 420), (imshape[1], 420), (imshape[1],660)]], dtype=np.int32)\n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "        \n",
    "    binary_output[(dir_grad >= thresh[0]) & (dir_grad <= thresh[1]) & (mask > 0)] = 1\n",
    "    return binary_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create test images from the challenge videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video test_videos/overpass.mp4\n",
      "[MoviePy] Writing video test_videos/overpass.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  3.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: test_videos/overpass.mp4 \n",
      "\n",
      "[MoviePy] >>>> Building video test_videos/pavement.mp4\n",
      "[MoviePy] Writing video test_videos/pavement.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: test_videos/pavement.mp4 \n",
      "\n",
      "[MoviePy] >>>> Building video test_videos/leaves.mp4\n",
      "[MoviePy] Writing video test_videos/leaves.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  3.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: test_videos/leaves.mp4 \n",
      "\n",
      "[MoviePy] >>>> Building video test_videos/shadows.mp4\n",
      "[MoviePy] Writing video test_videos/shadows.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: test_videos/shadows.mp4 \n",
      "\n",
      "reading image\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  False\n",
      "reading image\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  False\n",
      "reading image\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  False\n",
      "reading image\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  False\n"
     ]
    }
   ],
   "source": [
    "overpass = VideoFileClip(\"./challenge_video.mp4\").subclip(4.2,4.3)\n",
    "overpass.write_videofile('test_videos/overpass.mp4', audio=False)\n",
    "pavement = VideoFileClip(\"./challenge_video.mp4\").subclip(6,6.1)\n",
    "pavement.write_videofile('test_videos/pavement.mp4', audio=False)\n",
    "leaves = VideoFileClip(\"./harder_challenge_video.mp4\").subclip(3,3.1)\n",
    "leaves.write_videofile('test_videos/leaves.mp4', audio=False)\n",
    "shadows = VideoFileClip(\"./harder_challenge_video.mp4\").subclip(7,7.1)\n",
    "shadows.write_videofile('test_videos/shadows.mp4', audio=False)\n",
    "\n",
    "names =['overpass', 'pavement', 'leaves', 'shadows']\n",
    "for fname in names:\n",
    "    vidcap = cv2.VideoCapture('test_videos/%s.mp4' %(fname))\n",
    "    print('reading image')\n",
    "    success,image = vidcap.read()\n",
    "    count = 0\n",
    "    success = True\n",
    "    while success:\n",
    "      cv2.imwrite('test_images/%s_frame%d.jpg' %(fname, count), image)     \n",
    "      success,image = vidcap.read()\n",
    "      print('Read a new frame: ', success)\n",
    "      count += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First, I'll compute the camera calibration using chessboard images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('camera_cal/calibration*.jpg')\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6),None)\n",
    "\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        img = cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "        plt.imshow(img)\n",
    "        #cv2.imshow('img',img)\n",
    "        #cv2.waitKey(500)\n",
    "\n",
    "\n",
    "# TODO: Write a function that takes an image, object points, and image points\n",
    "# performs the camera calibration, image distortion correction and \n",
    "# returns the undistorted image\n",
    "img = cv2.imread('camera_cal/calibration1.jpg')\n",
    "undistorted = cal_undistort(img, objpoints, imgpoints)\n",
    "cv2.imwrite('camera_cal/undistorted.jpg', undistorted)\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=50)\n",
    "ax2.imshow(undistorted)\n",
    "ax2.set_title('Undistorted Image', fontsize=50)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Input and undistort raw images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading leaves_frame0.jpg\n",
      "reading leaves_frame1.jpg\n",
      "reading leaves_frame2.jpg\n",
      "reading overpass_frame0.jpg\n",
      "reading overpass_frame1.jpg\n",
      "reading overpass_frame2.jpg\n",
      "reading pavement_frame0.jpg\n",
      "reading pavement_frame1.jpg\n",
      "reading pavement_frame2.jpg\n",
      "reading shadows_frame0.jpg\n",
      "reading shadows_frame1.jpg\n",
      "reading shadows_frame2.jpg\n",
      "reading straight_lines1.jpg\n",
      "reading straight_lines2.jpg\n",
      "reading test1.jpg\n",
      "reading test2.jpg\n",
      "reading test3.jpg\n",
      "reading test4.jpg\n",
      "reading test5.jpg\n",
      "reading test6.jpg\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "file_list = os.listdir(\"test_images/\")\n",
    "#fig=plt.figure(figsize=(10, 80))\n",
    "i = 1\n",
    "\n",
    "for name in file_list:\n",
    "    image = cv2.imread('test_images/%s'  %(name))   #read in the image\n",
    "    print('reading %s' %(name))\n",
    "    undistorted = cal_undistort(image, objpoints, imgpoints)\n",
    "    cv2.imwrite('Undistorted_Test_Images/undistorted_%s'  %(name), undistorted)\n",
    "    \n",
    "b,g,r = cv2.split(image)       # get b,g,r\n",
    "rgb_image = cv2.merge([r,g,b])     # switch it to rgb\n",
    "b,g,r = cv2.split(undistorted)       # get b,g,r\n",
    "rgb_undistorted = cv2.merge([r,g,b])     # switch it to rgb\n",
    "\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(rgb_image)\n",
    "ax1.set_title('Original Image', fontsize=50)\n",
    "ax2.imshow(rgb_undistorted)\n",
    "ax2.set_title('Undistorted Image', fontsize=50)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "print('done')\n",
    "#gray = cv2.cvtColor(image,cv2.COLOR_RGB2GRAY) # grayscale the image\n",
    "#blur_gray = gaussian_blur(gray, 5)  #add gaussian blur\n",
    "#edges = cv2.Canny(blur_gray, 50, 150)  # add canny "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use color transforms, gradients, etc., to create a thresholded binary image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading 3\n",
      "0.0\n",
      "1.5707963267948966\n",
      "reading 4\n",
      "0.0\n",
      "1.5707963267948966\n",
      "reading 5\n",
      "0.0\n",
      "1.5707963267948966\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Combined')"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list = [3,4,5]\n",
    "sobel_kernel = 5\n",
    "chart=plt.figure(figsize=(24, 12))\n",
    "\n",
    "for name in file_list:\n",
    "    print('reading %s' %(name))\n",
    "    image = mpimg.imread('Undistorted_Test_Images/undistorted_test%s.jpg'  %(name))   #read in the image\n",
    "    \n",
    "    gray =  image[:,:,0]#cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) # 1) Convert to grayscale\n",
    "    blur_gray = gaussian_blur(gray, 5)  #add gaussian blur\n",
    "    sobel_x = np.absolute(cv2.Sobel(blur_gray, cv2.CV_64F, 1, 0,ksize=sobel_kernel))\n",
    "    sobel_y = np.absolute(cv2.Sobel(blur_gray, cv2.CV_64F, 0, 1,ksize=sobel_kernel))\n",
    "    mag_grad = np.sqrt(np.power(sobel_x,2)+np.power(sobel_y,2))\n",
    "    # = np.arctan2(sobel_y,sobel_x)\n",
    "    R = image[:,:,0]\n",
    "    G = image[:,:,1]\n",
    "    B = image[:,:,2]\n",
    "    hls = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "    H = hls[:,:,0]\n",
    "    L = hls[:,:,1]\n",
    "    S = hls[:,:,2]\n",
    "    \n",
    "    x_binary = threshold(sobel_x, 20, 60)\n",
    "    y_binary = threshold(sobel_y, 20, 60)\n",
    "    mag_binary = threshold(mag_grad, 35, 150)                      \n",
    "    Canny_binary = cv2.Canny(gray, 50, 150)  # add canny\n",
    "    dir_binary = dir_threshold(image, sobel_kernel=3, thresh=(1,1.6))\n",
    "    dir_interesting = ((Canny_binary > 0) & (dir_binary > 0) & (x_binary > 0))\n",
    "    r_binary = threshold(R, 200,255, False)\n",
    "    h_binary = threshold(H, 20, 100, False)\n",
    "    s_binary = threshold(S, 90, 255, False)\n",
    "    l_binary = threshold(L, 200, 255, False)\n",
    "\n",
    "    \n",
    "    #combining HLS colorspace to identify white and yellow lines.  I got inspiration from the HLS \n",
    "    #color thresholds lesson and from Tran's paper referenced above\n",
    "    white = (l_binary & (s_binary | r_binary))\n",
    "    yellow = (s_binary & h_binary)\n",
    "    combined = (white | yellow | dir_interesting)\n",
    "    \n",
    "    chart.add_subplot(3, 2, (name-2)*2-1)\n",
    "    plt.imshow(image)\n",
    "    chart.add_subplot(3, 2, (name-2)*2)\n",
    "    plt.imshow(combined)\n",
    "\n",
    "    \n",
    "    \n",
    "f, axes = plt.subplots(4, 2, figsize=(24, 12))\n",
    "f.tight_layout()\n",
    "\n",
    "axes[0,0].imshow(image)\n",
    "axes[0,0].set_title('Original Image', fontsize=20)\n",
    "\n",
    "axes[0,1].imshow(gray)\n",
    "axes[0,1].set_title('Grayscale', fontsize=20)\n",
    "\n",
    "axes[1,0].imshow(blur_gray)\n",
    "axes[1,0].set_title('Blurred Grayscale', fontsize=20)\n",
    "\n",
    "axes[1,1].imshow(x_binary)\n",
    "axes[1,1].set_title('SobelX Binary', fontsize=20)\n",
    "\n",
    "axes[2,0].imshow(y_binary)\n",
    "axes[2,0].set_title('SobelY Binary', fontsize=20)\n",
    "\n",
    "axes[2,1].imshow(mag_binary)\n",
    "axes[2,1].set_title('Magnitude Binary', fontsize=20)\n",
    "\n",
    "axes[3,0].imshow(dir_interesting)\n",
    "axes[3,0].set_title('Direction Binary', fontsize=20)\n",
    "\n",
    "axes[3,1].imshow(Canny_binary)\n",
    "axes[3,1].set_title('Canny Binary', fontsize=20)\n",
    "\n",
    "\n",
    "fig, color_axes = plt.subplots(3, 2, figsize=(24, 9))\n",
    "fig.tight_layout()\n",
    "\n",
    "color_axes[0,0].imshow(S)\n",
    "color_axes[0,0].set_title('S', fontsize=20)\n",
    "\n",
    "color_axes[0,1].imshow(s_binary)\n",
    "color_axes[0,1].set_title('S binary', fontsize=20)\n",
    "\n",
    "color_axes[1,0].imshow(H)\n",
    "color_axes[1,0].set_title('H', fontsize=20)\n",
    "\n",
    "color_axes[1,1].imshow(h_binary)\n",
    "color_axes[1,1].set_title('H binary', fontsize=20)\n",
    "\n",
    "color_axes[2,0].imshow(L)\n",
    "color_axes[2,0].set_title('L', fontsize=20)\n",
    "\n",
    "color_axes[2,1].imshow(l_binary)\n",
    "color_axes[2,1].set_title('L binary', fontsize=20)\n",
    "\n",
    "fig2, axes = plt.subplots(2, 2, figsize=(24, 9))\n",
    "fig2.tight_layout()\n",
    "\n",
    "axes[0,0].imshow(white)\n",
    "axes[0,0].set_title('White Lines', fontsize=20)\n",
    "\n",
    "axes[0,1].imshow(yellow)\n",
    "axes[0,1].set_title('Yellow Lines', fontsize=20)\n",
    "\n",
    "axes[1,0].imshow(image)\n",
    "axes[1,0].set_title('Original', fontsize=20)\n",
    "\n",
    "axes[1,1].imshow(combined)\n",
    "axes[1,1].set_title('Combined', fontsize=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
