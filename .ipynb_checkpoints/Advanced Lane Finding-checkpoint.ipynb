{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Lane Finding Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources\n",
    "extracting frames from video:  https://stackoverflow.com/questions/33311153/python-extracting-and-saving-video-frames\n",
    "a.\tReal time lane detection for autonomous vehicles, Assidiq et. al.\n",
    "b.\tSaad Bedros, Hough Transform and Thresholding lecture, University of Minnesota \n",
    "c.\tLane detection techniques review, Kaur and Kumar\n",
    "d.\tAn Adaptive Method for Lane Marking Detection Based on HSI Color Model, Tran and Cho\n",
    "e.\tLANE CHANGE DETECTION AND TRACKING FOR A SAFE-LANE APPROACH IN REAL TIME VISION BASED NAVIGATION SYSTEMS, Somasundaram, Ramachandran, Kavitha\n",
    "f.\tA Robust Lane Detection and Departure Warning System, Mrinal Haloi and Dinesh Babu Jayagopi\n",
    "g.\tSteerable filters\n",
    "h.\tA layered approach to robust lane detection at night, Hayes and Pankati\n",
    "i.\tSHADOW DETECTION USING COLOR AND EDGE INFORMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#command line functions\n",
    "#os.rmdir('../Undistorted Test Images')\n",
    "#os.mkdir('../Undistorted_Test_Images')\n",
    "#os.remove('../overpass.mp4')\n",
    "#os.remove('../pavement.mp4')\n",
    "#os.remove('../leaves.mp4')\n",
    "#os.remove('../shadows.mp4')\n",
    "#os.remove('../test_images/undistorted_straight_lines2.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib qt\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create test images from the challenge videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video test_videos/overpass.mp4\n",
      "[MoviePy] Writing video test_videos/overpass.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  3.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: test_videos/overpass.mp4 \n",
      "\n",
      "[MoviePy] >>>> Building video test_videos/pavement.mp4\n",
      "[MoviePy] Writing video test_videos/pavement.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: test_videos/pavement.mp4 \n",
      "\n",
      "[MoviePy] >>>> Building video test_videos/leaves.mp4\n",
      "[MoviePy] Writing video test_videos/leaves.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  3.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: test_videos/leaves.mp4 \n",
      "\n",
      "[MoviePy] >>>> Building video test_videos/shadows.mp4\n",
      "[MoviePy] Writing video test_videos/shadows.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: test_videos/shadows.mp4 \n",
      "\n",
      "reading image\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  False\n",
      "reading image\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  False\n",
      "reading image\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  False\n",
      "reading image\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  False\n"
     ]
    }
   ],
   "source": [
    "overpass = VideoFileClip(\"./challenge_video.mp4\").subclip(4.2,4.3)\n",
    "overpass.write_videofile('test_videos/overpass.mp4', audio=False)\n",
    "pavement = VideoFileClip(\"./challenge_video.mp4\").subclip(6,6.1)\n",
    "pavement.write_videofile('test_videos/pavement.mp4', audio=False)\n",
    "leaves = VideoFileClip(\"./harder_challenge_video.mp4\").subclip(3,3.1)\n",
    "leaves.write_videofile('test_videos/leaves.mp4', audio=False)\n",
    "shadows = VideoFileClip(\"./harder_challenge_video.mp4\").subclip(7,7.1)\n",
    "shadows.write_videofile('test_videos/shadows.mp4', audio=False)\n",
    "\n",
    "names =['overpass', 'pavement', 'leaves', 'shadows']\n",
    "for fname in names:\n",
    "    vidcap = cv2.VideoCapture('test_videos/%s.mp4' %(fname))\n",
    "    print('reading image')\n",
    "    success,image = vidcap.read()\n",
    "    count = 0\n",
    "    success = True\n",
    "    while success:\n",
    "      cv2.imwrite('test_images/%s_frame%d.jpg' %(fname, count), image)     \n",
    "      success,image = vidcap.read()\n",
    "      print('Read a new frame: ', success)\n",
    "      count += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_undistort(img, objpoints, imgpoints):\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    return undist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First, I'll compute the camera calibration using chessboard images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('camera_cal/calibration*.jpg')\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6),None)\n",
    "\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        img = cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "        plt.imshow(img)\n",
    "        #cv2.imshow('img',img)\n",
    "        #cv2.waitKey(500)\n",
    "\n",
    "\n",
    "# TODO: Write a function that takes an image, object points, and image points\n",
    "# performs the camera calibration, image distortion correction and \n",
    "# returns the undistorted image\n",
    "img = cv2.imread('camera_cal/calibration1.jpg')\n",
    "undistorted = cal_undistort(img, objpoints, imgpoints)\n",
    "cv2.imwrite('camera_cal/undistorted.jpg', undistorted)\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=50)\n",
    "ax2.imshow(undistorted)\n",
    "ax2.set_title('Undistorted Image', fontsize=50)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Input and correct raw images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading leaves_frame0.jpg\n",
      "reading leaves_frame1.jpg\n",
      "reading leaves_frame2.jpg\n",
      "reading overpass_frame0.jpg\n",
      "reading overpass_frame1.jpg\n",
      "reading overpass_frame2.jpg\n",
      "reading pavement_frame0.jpg\n",
      "reading pavement_frame1.jpg\n",
      "reading pavement_frame2.jpg\n",
      "reading shadows_frame0.jpg\n",
      "reading shadows_frame1.jpg\n",
      "reading shadows_frame2.jpg\n",
      "reading straight_lines1.jpg\n",
      "reading straight_lines2.jpg\n",
      "reading test1.jpg\n",
      "reading test2.jpg\n",
      "reading test3.jpg\n",
      "reading test4.jpg\n",
      "reading test5.jpg\n",
      "reading test6.jpg\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "file_list = os.listdir(\"test_images/\")\n",
    "#fig=plt.figure(figsize=(10, 80))\n",
    "i = 1\n",
    "\n",
    "for name in file_list:\n",
    "    image = cv2.imread('test_images/%s'  %(name))   #read in the image\n",
    "    print('reading %s' %(name))\n",
    "    undistorted = cal_undistort(image, objpoints, imgpoints)\n",
    "    cv2.imwrite('Undistorted_Test_Images/undistorted_%s'  %(name), undistorted)\n",
    "    \n",
    "b,g,r = cv2.split(image)       # get b,g,r\n",
    "rgb_image = cv2.merge([r,g,b])     # switch it to rgb\n",
    "b,g,r = cv2.split(undistorted)       # get b,g,r\n",
    "rgb_undistorted = cv2.merge([r,g,b])     # switch it to rgb\n",
    "\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(rgb_image)\n",
    "ax1.set_title('Original Image', fontsize=50)\n",
    "ax2.imshow(rgb_undistorted)\n",
    "ax2.set_title('Undistorted Image', fontsize=50)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "print('done')\n",
    "#gray = cv2.cvtColor(image,cv2.COLOR_RGB2GRAY) # grayscale the image\n",
    "#blur_gray = gaussian_blur(gray, 5)  #add gaussian blur\n",
    "#edges = cv2.Canny(blur_gray, 50, 150)  # add canny "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
